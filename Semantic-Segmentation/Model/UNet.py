# -*- coding: utf-8 -*-
"""Rosalind_ComputerVisionProjectGroup12!.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dhJCvXdGCULogbcL-yrPBo5CWO4tr-Nj

### Disaster-Resilient Military Base Damage Assessment with Autonomous Object Tracking

1. Data Loading and Visualization:
"""

import os
import cv2
import matplotlib.pyplot as plt

# Mount Google Drive (if needed)
from google.colab import drive
drive.mount('/content/drive')

# Path to your dataset
data_path = '/content/drive/MyDrive/RescueNet' #change this to your path.

# Load a sample image and its label mask
train_org_img_path = os.path.join(data_path, 'train/train-org-img')
train_label_img_path = os.path.join(data_path, 'train/train-label-img')

sample_image_file = os.listdir(train_org_img_path)[0]
sample_label_file = os.listdir(train_label_img_path)[0]

sample_image = cv2.imread(os.path.join(train_org_img_path, sample_image_file))
sample_label = cv2.imread(os.path.join(train_label_img_path, sample_label_file))

# Convert BGR to RGB for matplotlib
sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)
sample_label = cv2.cvtColor(sample_label, cv2.COLOR_BGR2RGB)

# Display the image and label mask
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(sample_image)
plt.title('Sample Image')
plt.subplot(1, 2, 2)
plt.imshow(sample_label)
plt.title('Label Mask')
plt.show()

"""Experimenting U-Net"""

# Mount Google Drive (if needed)
from google.colab import drive
drive.mount('/content/drive')

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load label image (grayscale)
mask = cv2.imread('/content/drive/MyDrive/RescueNet/train/train-label-img/10778_lab.png', cv2.IMREAD_UNCHANGED)

# Display original mask
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.title("Raw Label (Looks Black)")
plt.imshow(mask, cmap='gray')
plt.axis('off')

# Display with color map for clarity
plt.subplot(1,2,2)
plt.title("Label with Color Map")
plt.imshow(mask, cmap='nipy_spectral')  # or 'tab20', 'jet', etc.
plt.axis('off')
plt.show()

!pip install tensorflow opencv-python matplotlib albumentations

import os
import numpy as np
import cv2
from tensorflow.keras.utils import Sequence

class RescuenetDataset(Sequence):
    def __init__(self, image_dir, mask_dir, batch_size=8, img_size=(256, 256)):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.image_ids = sorted([
            f for f in os.listdir(image_dir)
            if f.endswith('.png') or f.endswith('.jpg')
        ])
        self.batch_size = batch_size
        self.img_size = img_size

    def __len__(self):
        return len(self.image_ids) // self.batch_size

    def __getitem__(self, idx):
      batch_x = self.image_ids[idx * self.batch_size:(idx + 1) * self.batch_size]
      images, masks = [], []

      for img_filename in batch_x:
          img_id = os.path.splitext(img_filename)[0]  # '11078'
          img_path = os.path.join(self.image_dir, f"{img_id}.jpg")
          mask_path = os.path.join(self.mask_dir, f"{img_id}_lab.png")

          # Load image
          img = cv2.imread(img_path)
          if img is None:
              print(f"Image not found or failed to load: {img_path}")
              continue

          # Load mask
          mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
          if mask is None:
              print(f"Mask not found or failed to load: {mask_path}")
              continue

          # Resize
          img = cv2.resize(img, self.img_size)
          mask = cv2.resize(mask, self.img_size)

          # Normalize
          img = img / 255.0
          mask = mask / 255.0
          mask = np.expand_dims(mask, axis=-1)

          images.append(img)
          masks.append(mask)

      return np.array(images), np.array(masks)

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate
from tensorflow.keras.models import Model

def build_unet(input_size=(256, 256, 3)):
    inputs = Input(input_size)
    c1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    c1 = Conv2D(64, 3, activation='relu', padding='same')(c1)
    p1 = MaxPooling2D()(c1)

    c2 = Conv2D(128, 3, activation='relu', padding='same')(p1)
    c2 = Conv2D(128, 3, activation='relu', padding='same')(c2)
    p2 = MaxPooling2D()(c2)

    c3 = Conv2D(256, 3, activation='relu', padding='same')(p2)
    c3 = Conv2D(256, 3, activation='relu', padding='same')(c3)

    u1 = UpSampling2D()(c3)
    u1 = concatenate([u1, c2])
    c4 = Conv2D(128, 3, activation='relu', padding='same')(u1)
    c4 = Conv2D(128, 3, activation='relu', padding='same')(c4)

    u2 = UpSampling2D()(c4)
    u2 = concatenate([u2, c1])
    c5 = Conv2D(64, 3, activation='relu', padding='same')(u2)
    c5 = Conv2D(64, 3, activation='relu', padding='same')(c5)

    outputs = Conv2D(1, 1, activation='sigmoid')(c5)
    return Model(inputs, outputs)

train_gen = RescuenetDataset(
    image_dir="/content/drive/MyDrive/RescueNet/train/train-org-img",
    mask_dir="/content/drive/MyDrive/RescueNet/train/train-label-img",
    batch_size=8
)

val_gen = RescuenetDataset(
    image_dir="/content/drive/MyDrive/RescueNet/val/val-org-img",
    mask_dir="/content/drive/MyDrive/RescueNet/val/val-label-img",
    batch_size=8
)

model = build_unet()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

model.fit(train_gen, validation_data=val_gen, epochs=10)

model.save('/content/unet_rescuenet.h5')

from tensorflow.keras.callbacks import ModelCheckpoint

checkpoint = ModelCheckpoint(
    'best_unet_model.h5',
    monitor='val_loss',       # or 'val_accuracy'
    save_best_only=True,
    verbose=1
)

# Train with checkpoint
model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10,
    callbacks=[checkpoint]
)

val_loss, val_accuracy = model.evaluate(val_gen)
print(f"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}")

import matplotlib.pyplot as plt

# Get one batch from val generator
X_val, y_val = val_gen[1]

# Predict mask for the first image in the batch
pred_mask = model.predict(np.expand_dims(X_val[0], axis=0))[0]

# Threshold the mask (optional: to binarize)
pred_mask_bin = (pred_mask > 0.5).astype(np.uint8)

# Plot original image, ground truth, and prediction
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.title("Input Image")
plt.imshow(X_val[0])
plt.axis('off')

plt.subplot(1, 3, 2)
plt.title("Ground Truth Mask")
plt.imshow(y_val[0].squeeze(), cmap='gray')
plt.axis('off')

plt.subplot(1, 3, 3)
plt.title("Predicted Mask")
plt.imshow(pred_mask_bin.squeeze(), cmap='gray')
plt.axis('off')

plt.tight_layout()
plt.show()

def evaluate_segmentation_metrics(model, data_gen, threshold=0.5):
    iou_scores = []
    precision_scores = []
    recall_scores = []
    f1_scores = []

    for i in range(len(data_gen)):
        imgs, masks_true = data_gen[i]
        preds = model.predict(imgs)

        # Binarize predictions and ground truths
        preds_bin = (preds > threshold).astype(np.uint8)
        masks_true_bin = (masks_true > 0.5).astype(np.uint8)

        for pred, true in zip(preds_bin, masks_true_bin):
            pred = pred.squeeze()
            true = true.squeeze()

            intersection = np.logical_and(pred, true).sum()
            union = np.logical_or(pred, true).sum()
            tp = intersection
            fp = np.logical_and(pred == 1, true == 0).sum()
            fn = np.logical_and(pred == 0, true == 1).sum()

            iou = tp / (union + 1e-6)
            precision = tp / (tp + fp + 1e-6)
            recall = tp / (tp + fn + 1e-6)
            f1 = 2 * precision * recall / (precision + recall + 1e-6)

            iou_scores.append(iou)
            precision_scores.append(precision)
            recall_scores.append(recall)
            f1_scores.append(f1)

    print(f"Mean IoU:       {np.mean(iou_scores):.4f}")
    print(f"Mean Precision: {np.mean(precision_scores):.4f}")
    print(f"Mean Recall:    {np.mean(recall_scores):.4f}")
    print(f"Mean F1 Score:  {np.mean(f1_scores):.4f}")

evaluate_segmentation_metrics(model, val_gen)

from sklearn.metrics import precision_score, recall_score, jaccard_score

y_true = masks.flatten()
y_pred = (preds > 0.5).astype(np.uint8).flatten()

precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
iou = jaccard_score(y_true, y_pred)
print(f"Precision: {precision}, Recall: {recall}, IoU: {iou}")

import os
import numpy as np
import cv2
import tensorflow as tf
from tensorflow.keras.utils import Sequence
import segmentation_models as sm
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# --- Dataset Generator ---
class RescuenetDataset(Sequence):
    def __init__(self, image_dir, mask_dir, image_ids, batch_size=8, img_size=(256, 256), num_classes=12):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.image_ids = image_ids
        self.batch_size = batch_size
        self.img_size = img_size
        self.num_classes = num_classes

    def __len__(self):
        return int(np.ceil(len(self.image_ids) / self.batch_size))

    def __getitem__(self, idx):
        batch_ids = self.image_ids[idx * self.batch_size:(idx + 1) * self.batch_size]
        images, masks = [], []

        for img_id in batch_ids:
            img_path = os.path.join(self.image_dir, f"{img_id}.jpg")
            mask_path = os.path.join(self.mask_dir, f"{img_id}_lab.png")

            img = cv2.imread(img_path)
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

            if img is None or mask is None:
                continue

            img = cv2.resize(img, self.img_size)
            mask = cv2.resize(mask, self.img_size, interpolation=cv2.INTER_NEAREST)

            img = img / 255.0
            mask = tf.keras.utils.to_categorical(mask, num_classes=self.num_classes)

            images.append(img)
            masks.append(mask)

        return np.array(images), np.array(masks)

# --- Prepare Dataset ---
image_dir = 'RescueNet/train/train-org-img'
mask_dir = 'RescueNet/train/train-label-img'

all_ids = [os.path.splitext(f)[0] for f in os.listdir(image_dir) if f.endswith('.jpg')]
train_ids, val_ids = train_test_split(all_ids, test_size=0.2, random_state=42)

train_gen = RescuenetDataset(image_dir, mask_dir, train_ids)
val_gen = RescuenetDataset(image_dir, mask_dir, val_ids)

# --- Build DeepLabV3+ Model ---
sm.set_framework('tf.keras')
sm.framework()

model = sm.DeepLabV3Plus(
    backbone_name='resnet50',
    encoder_weights='imagenet',
    classes=12,
    activation='softmax'
)

model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-4),
    loss=sm.losses.categorical_crossentropy,
    metrics=[sm.metrics.iou_score]
)

# --- Train Model ---
history = model.fit(train_gen, validation_data=val_gen, epochs=25)

# --- Save Model ---
model.save('deeplabv3plus_rescuenet.h5')

# --- Predict on Sample ---
sample_img, sample_mask = val_gen[0]
pred = model.predict(np.expand_dims(sample_img[0], axis=0))
pred_mask = np.argmax(pred[0], axis=-1)
true_mask = np.argmax(sample_mask[0], axis=-1)

plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.title("Image")
plt.imshow(sample_img[0])

plt.subplot(1, 3, 2)
plt.title("True Mask")
plt.imshow(true_mask)

plt.subplot(1, 3, 3)
plt.title("Predicted Mask")
plt.imshow(pred_mask)
plt.tight_layout()
plt.show()
